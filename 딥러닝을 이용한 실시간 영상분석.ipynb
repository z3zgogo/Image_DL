{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 학습데이터 수집"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- id(정수로 0부터 가능)로 얼굴인식 데이터 수집"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "\n",
    "cam = cv2.VideoCapture(0)\n",
    "cam.set(3, 640) # set video width\n",
    "cam.set(4, 480) # set video height\n",
    "face_detector = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "\n",
    "# For each person, enter one numeric face id \n",
    "face_id = input('\\n enter user id end press <return> ==>  ')\n",
    "print(\"\\n [INFO] Initializing face capture. Look the camera and wait ...\")\n",
    "\n",
    "# Initialize individual sampling face count\n",
    "count = 0\n",
    "while(True):\n",
    "    ret, img = cam.read()\n",
    "    #img = cv2.flip(img, -1) # flip video image vertically\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_detector.detectMultiScale(gray, 1.3, 5)\n",
    "    for (x,y,w,h) in faces:\n",
    "        cv2.rectangle(img, (x,y), (x+w,y+h), (255,0,0), 2)     \n",
    "        count += 1\n",
    "        # Save the captured image into the datasets folder\n",
    "        cv2.imwrite(\"dataset/User.\" + str(face_id) + '.' + str(count) + \".jpg\", gray[y:y+h,x:x+w])\n",
    "        cv2.imshow('image', img)\n",
    "    k = cv2.waitKey(100) & 0xff # Press 'ESC' for exiting video\n",
    "    if k == 27:\n",
    "        break\n",
    "    elif count >= 500: # Take 30 face sample and stop video\n",
    "        break\n",
    "# Do a bit of cleanup\n",
    "print(\"\\n [INFO] Exiting Program and cleanup stuff\")\n",
    "cam.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 수집된 데이터 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "# Path for face image database\n",
    "path = 'dataset'\n",
    "recognizer = cv2.face.LBPHFaceRecognizer_create()\n",
    "detector = cv2.CascadeClassifier(\"haarcascade_frontalface_default.xml\");\n",
    "\n",
    "# function to get the images and label data\n",
    "def getImagesAndLabels(path):\n",
    "    imagePaths = [os.path.join(path,f) for f in os.listdir(path)]     \n",
    "    faceSamples=[]\n",
    "    ids = []\n",
    "    for imagePath in imagePaths:\n",
    "        PIL_img = Image.open(imagePath).convert('L') # convert it to grayscale\n",
    "        img_numpy = np.array(PIL_img,'uint8')\n",
    "        id = int(os.path.split(imagePath)[-1].split(\".\")[1])\n",
    "        faces = detector.detectMultiScale(img_numpy)\n",
    "        for (x,y,w,h) in faces:\n",
    "            faceSamples.append(img_numpy[y:y+h,x:x+w])\n",
    "            ids.append(id)\n",
    "    return faceSamples,ids\n",
    "\n",
    "print (\"\\n [INFO] Training faces. It will take a few seconds. Wait ...\")\n",
    "faces,ids = getImagesAndLabels(path)\n",
    "recognizer.train(faces, np.array(ids))\n",
    "\n",
    "# Save the model into trainer/trainer.yml\n",
    "recognizer.write('trainer/trainer.yml') # recognizer.save() worked on Mac, but not on Pi\n",
    "# Print the numer of faces trained and end program\n",
    "print(\"\\n [INFO] {0} faces trained. Exiting Program\".format(len(np.unique(ids))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# openCV를 이용하여 실시간 얼굴인식"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- id를 부여(0~3)하여 조원인식\n",
    "- 키보드 i 버튼을 이용하여 smile, angry 필터효과 on/off\n",
    "- smile, angry 각 다른 필터적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "웃어보세요\n",
      "웃어보세요\n",
      "웃어보세요\n",
      "웃어보세요\n",
      "웃어보세요\n",
      "웃어보세요\n",
      "웃어보세요\n",
      "웃어보세요\n",
      "웃어보세요\n",
      "웃어보세요\n",
      "웃어보세요\n",
      "웃어보세요\n",
      "웃어보세요\n",
      "웃어보세요\n",
      "웃어보세요\n",
      "웃어보세요\n",
      "웃어보세요\n",
      "웃어보세요\n",
      "웃어보세요\n",
      "웃어보세요\n",
      "웃어보세요\n",
      "웃어보세요\n",
      "웃어보세요\n",
      "웃어보세요\n",
      "웃어보세요\n",
      "웃어보세요\n",
      "웃어보세요\n",
      "웃어보세요\n",
      "웃어보세요\n",
      "웃어보세요\n",
      "웃어보세요\n",
      "웃어보세요\n",
      "웃어보세요\n",
      "웃어보세요\n",
      "웃어보세요\n",
      "웃어보세요\n",
      "웃어보세요\n",
      "웃어보세요\n",
      "웃어보세요\n",
      "웃어보세요\n",
      "웃어보세요\n",
      "웃어보세요\n",
      "웃어보세요\n",
      "웃어보세요\n",
      "웃어보세요\n",
      "웃어보세요\n",
      "웃어보세요\n",
      "웃어보세요\n",
      "웃어보세요\n",
      "웃어보세요\n",
      "웃어보세요\n",
      "웃어보세요\n",
      "웃어보세요\n",
      "웃어보세요\n",
      "웃어보세요\n",
      "웃어보세요\n",
      "웃어보세요\n",
      "웃어보세요\n",
      "웃어보세요\n",
      "웃어보세요\n",
      "웃어보세요\n",
      "웃어보세요\n",
      "종료\n"
     ]
    }
   ],
   "source": [
    "import cv2, os\n",
    "import dlib\n",
    "import sys\n",
    "import numpy as np\n",
    "import time\n",
    "import datetime\n",
    "import os\n",
    "from keras.utils import np_utils\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import imutils\n",
    "import pytesseract\n",
    "from keras.models import load_model\n",
    "from twilio.rest import Client\n",
    "\n",
    "# 마스크 라벨\n",
    "labels_dict={1:'smile', 0:'angry'}\n",
    "color_dict={0:(0,255,0),1:(0,0,255)}\n",
    "\n",
    "# avi\n",
    "fourcc = cv2.VideoWriter_fourcc(*'DIVX')\n",
    "\n",
    "# 텍스트표시\n",
    "font = cv2.FONT_ITALIC\n",
    "\n",
    "# face 분류기 로드\n",
    "face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "smile_cascade = cv2.CascadeClassifier('haarcascade_smile.xml') \n",
    "\n",
    "# 실시간 개인분류 학습모델\n",
    "recognizer = cv2.face.LBPHFaceRecognizer_create()\n",
    "recognizer.read('trainer/trainer.yml')\n",
    "\n",
    "# open CV\n",
    "smile_detact = False\n",
    "source=cv2.VideoCapture(0)\n",
    "time.sleep(3) #warming up\n",
    "source.set(3,640)\n",
    "source.set(4,480)\n",
    "record = False\n",
    "\n",
    "# Define min window size to be recognized as a face\n",
    "minW = 0.1*source.get(3)\n",
    "minH = 0.1*source.get(4)\n",
    "\n",
    "# 스마일 - 모델\n",
    "model = load_model('059-0.1275.model')\n",
    "\n",
    "# 개인구분 ID 및 이름\n",
    "id = 0, 1, 2, 3\n",
    "# names related to ids: example ==> loze: id=1,  etc\n",
    "names = ['SY', 'JM', 'HS', 'BJ']\n",
    "\n",
    "# twilio\n",
    "#account_sid = 'Twilio API'\n",
    "#auth_token = 'Twilio API'\n",
    "\n",
    "# mask_이미지사진\n",
    "s_mask = cv2.imread('./mask/7.png') # smile 필터\n",
    "a_mask = cv2.imread('./mask/10.png') # angry 필터\n",
    "sh_mask, sw_mask = s_mask.shape[:2]\n",
    "ah_mask, aw_mask = s_mask.shape[:2]\n",
    "\n",
    "if face_cascade.empty():\n",
    "    raise IOError('Unable to load the face cascade classifier xml file')\n",
    "\n",
    "while True:\n",
    "    ret,frame = source.read()\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    face_rects = face_cascade.detectMultiScale(gray,\n",
    "                                               scaleFactor=1.2,\n",
    "                                               minNeighbors=5,\n",
    "                                               minSize=(int(minW), int(minH)))\n",
    "    if not ret:\n",
    "        break\n",
    "        #frame = cv2.resize(frame, None, fx=scaling_factor, fy=scaling_factor, interpolation=cv2.INTER_AREA)\n",
    "    \n",
    "    if smile_detact:\n",
    "        info = \"Smile Detention ON\"\n",
    "    else:\n",
    "        info = \"Smile Detection OFF\"\n",
    "    \n",
    "    cv2.putText(frame, info, (5,15), font, 0.5, (255,0, 255),1)\n",
    "    \n",
    "    for (x, y, w, h) in face_rects:\n",
    "        center = (x + w // 2, y + h // 2)\n",
    "        #frame = cv2.ellipse(frame, center, (w // 2, h // 2), 0, 0, 360, (255, 0, 255), 4)\n",
    "        #cv2.putText(frame, \"Detected Face\", (x-5, y-5), font, 0.5, (255,255,0),2)\n",
    "        \n",
    "        face_img=gray[y:y+w,x:x+w]\n",
    "        resized=cv2.resize(face_img,(100,100))\n",
    "        normalized=resized/255.0\n",
    "        reshaped=np.reshape(normalized,(1,100,100,1))\n",
    "        result=model.predict(reshaped)\n",
    "        \n",
    "        label=np.argmax(result,axis=1)[0]\n",
    "        #cv2.rectangle(frame,(x,y),(x+w,y+h),color_dict[label],2)\n",
    "        #cv2.rectangle(frame,(x,y-40),(x+w,y),color_dict[label],-1)\n",
    "        \n",
    "        #cv2.rectangle(img, (x,y), (x+w,y+h), (0,255,0), 2)\n",
    "        id, confidence = recognizer.predict(gray[y:y+h,x:x+w])\n",
    "        \n",
    "        # Check if confidence is less them 100 ==> \"0\" is perfect match\n",
    "        if (confidence < 100):\n",
    "            id = names[id]\n",
    "            confidence = \"  {0}%\".format(round(100 - confidence))\n",
    "        else:\n",
    "            id = \"unknown\"\n",
    "            confidence = \"  {0}%\".format(round(100 - confidence))\n",
    "        \n",
    "        cv2.putText(frame, str(id), (x+90, y-45), font, 1, (0,216,255), 3)\n",
    "        cv2.putText(frame, str(confidence), (x+80,y-30), font, 0.5, (0,216,255), 1)\n",
    "                                               \n",
    "        if(labels_dict[label] == 'angry'):\n",
    "            print(\"웃어보세요\")\n",
    "            \n",
    "        else:\n",
    "            #cv2.imwrite(\"../data/capture/\" + str(now) + \".png\", frame)\n",
    "            #client = Client(account_sid, auth_token)\n",
    "            #message = client.messages.create(\n",
    "            #            to=\"+821021277767\", \n",
    "            #            from_=\"+19092807561\",\n",
    "            #            body=\"마스크 쓰세요\")\n",
    "            print(\"웃는모습이 최고에요 / capture or send SMS\") \n",
    "            \n",
    "        cv2.putText(\n",
    "            frame, \"{}: {:.2f}%\".format(labels_dict[label], np.max(result) * 100),\n",
    "            (x, y-10),\n",
    "            cv2.FONT_HERSHEY_SIMPLEX,0.6,(255,255,255),2)\n",
    "        \n",
    "        if smile_detact: \n",
    "            roi_gray = gray[y:y+h, x:x+w]\n",
    "            roi_color = frame[y:y+h, x:x+w]\n",
    "            \n",
    "            smiles = smile_cascade.detectMultiScale(roi_gray,\n",
    "                                                    scaleFactor=1.5,\n",
    "                                                    minNeighbors=15,\n",
    "                                                    minSize=(25,25))\n",
    "            for (xx, yy, ww, hh) in smiles: \n",
    "                #cv2.rectangle(roi_color, (xx, yy), ((xx + ww), (yy + hh)), (0, 255, 0), 2)\n",
    "                \n",
    "                if(labels_dict[label] == 'smile'):\n",
    "                    if h > 0 and w > 0:\n",
    "                        x = int(x -w*0.1)\n",
    "                        y = int(y -h*0.35)\n",
    "                        w = int(1.2 * w)\n",
    "                        h = int(1.2 * h)\n",
    "                    \n",
    "                        frame_roi = frame[y:y + h, x:x + w]\n",
    "                        face_mask_small = cv2.resize(s_mask, (w, h), interpolation=cv2.INTER_AREA)\n",
    "                        gray_mask = cv2.cvtColor(face_mask_small, cv2.COLOR_BGR2GRAY)\n",
    "                        ret, mask = cv2.threshold(gray_mask, 240, 255, cv2.THRESH_TRUNC)\n",
    "                        #cv2.THRESH_BINARY_INV / cv2.THRESH_TRUNC\n",
    "\n",
    "                    mask_inv = cv2.bitwise_not(mask)\n",
    "                    masked_face = cv2.bitwise_and(face_mask_small, face_mask_small, mask=mask)\n",
    "                    masked_frame = cv2.bitwise_and(frame_roi, frame_roi, mask=mask_inv)\n",
    "                    frame[y:y + h, x:x + w] = cv2.add(masked_face, masked_frame)\n",
    "                    \n",
    "                elif(labels_dict[label] == 'angry'):\n",
    "                    if h > 0 and w > 0:\n",
    "                        x = int(x -w*0.1)\n",
    "                        y = int(y -h*0.35)\n",
    "                        w = int(1.2 * w)\n",
    "                        h = int(1.2 * h)\n",
    "                    \n",
    "                        frame_roi = frame[y:y + h, x:x + w]\n",
    "                        face_mask_small = cv2.resize(a_mask, (w, h), interpolation=cv2.INTER_AREA)\n",
    "                        gray_mask = cv2.cvtColor(face_mask_small, cv2.COLOR_BGR2GRAY)\n",
    "                        ret, mask = cv2.threshold(gray_mask, 240, 255, cv2.THRESH_TRUNC)\n",
    "                        #cv2.THRESH_BINARY_INV / cv2.THRESH_TRUNC\n",
    "\n",
    "                    mask_inv = cv2.bitwise_not(mask)\n",
    "                    masked_face = cv2.bitwise_and(face_mask_small, face_mask_small, mask=mask)\n",
    "                    masked_frame = cv2.bitwise_and(frame_roi, frame_roi, mask=mask_inv)\n",
    "                    frame[y:y + h, x:x + w] = cv2.add(masked_face, masked_frame)\n",
    "    \n",
    "    key = cv2.waitKey(33)\n",
    "    cv2.imshow('Face Detector', frame)\n",
    "    now = datetime.datetime.now().strftime(\"%d_%H-%M-%S\") #사진저장\n",
    "    \n",
    "    if key == 27: # ESC\n",
    "        #os.startfile(\"capture\")\n",
    "        print(\"종료\")\n",
    "        break\n",
    "    elif key == ord('i'):\n",
    "        smile_detact = not smile_detact\n",
    "    elif key == 99: # C\n",
    "        print(\"캡쳐\")\n",
    "        cv2.imwrite(\"capture/\" + str(now) + '-' + str(count) + \".png\", frame)\n",
    "    elif key == 115: # S\n",
    "        print(\"녹화 시작\")\n",
    "        record = True\n",
    "        out = cv2.VideoWriter(\"capture/\" + str(now) + \".avi\", fourcc, 20, (640, 480))\n",
    "    elif key == 122: # Z\n",
    "        print(\"녹화 중지\")\n",
    "\n",
    "        record = False\n",
    "        out.release()\n",
    "        \n",
    "    if record == True:\n",
    "        out.write(frame)\n",
    "\n",
    "source.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
