{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 얼굴잠금해제"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- https://blog.naver.com/chandong83/221436424539"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Facial_Recognition_Part1.py\n",
    "- 사진 100장찍고 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Face not Found\n",
      "Face not Found\n",
      "Face not Found\n",
      "Face not Found\n",
      "Face not Found\n",
      "Face not Found\n",
      "Face not Found\n",
      "Face not Found\n",
      "Face not Found\n",
      "Face not Found\n",
      "Colleting Samples Complete!!!\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "#얼국 인식용 xml 파일 \n",
    "face_classifier = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "\n",
    "#전체 사진에서 얼굴 부위만 잘라 리턴\n",
    "def face_extractor(img):\n",
    "    #흑백처리 \n",
    "    gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    #얼굴 찾기 \n",
    "    faces = face_classifier.detectMultiScale(gray,1.3,5)\n",
    "    #찾은 얼굴이 없으면 None으로 리턴 \n",
    "    if faces is():\n",
    "        return None\n",
    "    #얼굴들이 있으면 \n",
    "    for(x,y,w,h) in faces:\n",
    "        #해당 얼굴 크기만큼 cropped_face에 잘라 넣기 \n",
    "        #근데... 얼굴이 2개 이상 감지되면??\n",
    "        #가장 마지막의 얼굴만 남을 듯\n",
    "        cropped_face = img[y:y+h, x:x+w]\n",
    "    #cropped_face 리턴 \n",
    "    return cropped_face\n",
    "\n",
    "#카메라 실행 \n",
    "cap = cv2.VideoCapture(0)\n",
    "#저장할 이미지 카운트 변수 \n",
    "count = 0\n",
    "while True:\n",
    "    #카메라로 부터 사진 1장 얻기 \n",
    "    ret, frame = cap.read()\n",
    "    #얼굴 감지 하여 얼굴만 가져오기 \n",
    "    if face_extractor(frame) is not None:\n",
    "        count+=1\n",
    "        #얼굴 이미지 크기를 200x200으로 조정 \n",
    "        face = cv2.resize(face_extractor(frame),(200,200))\n",
    "        #조정된 이미지를 흑백으로 변환 \n",
    "        face = cv2.cvtColor(face, cv2.COLOR_BGR2GRAY)\n",
    "        #faces폴더에 jpg파일로 저장 \n",
    "        # ex > faces/user0.jpg   faces/user1.jpg ....\n",
    "        file_name_path = 'faces/user'+str(count)+'.jpg'          \n",
    "        cv2.imwrite(file_name_path,face)\n",
    "        \n",
    "        #화면에 얼굴과 현재 저장 개수 표시          \n",
    "        cv2.putText(face,str(count),(50,50),cv2.FONT_HERSHEY_COMPLEX,1,(0,255,0),2)\n",
    "        cv2.imshow('Face Cropper',face)\n",
    "    else:\n",
    "        print(\"Face not Found\")\n",
    "        pass\n",
    "\n",
    "    if cv2.waitKey(1)==13 or count==10:\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "print('Colleting Samples Complete!!!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Facial_Recognition_Part2.py\n",
    "- 사진으로 모델만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Training Complete!!!!!\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "data_path = 'faces/'\n",
    "#faces폴더에 있는 파일 리스트 얻기 \n",
    "onlyfiles = [f for f in listdir(data_path) if isfile(join(data_path,f))]\n",
    "\n",
    "#데이터와 매칭될 라벨 변수 \n",
    "Training_Data, Labels = [], []\n",
    "\n",
    "#파일 개수 만큼 루프 \n",
    "for i, files in enumerate(onlyfiles):    \n",
    "    image_path = data_path + onlyfiles[i]\n",
    "    #이미지 불러오기 \n",
    "    images = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    #이미지 파일이 아니거나 못 읽어 왔다면 무시\n",
    "    if images is None:\n",
    "        continue    \n",
    "    #Training_Data 리스트에 이미지를 바이트 배열로 추가 \n",
    "    Training_Data.append(np.asarray(images, dtype=np.uint8))\n",
    "    #Labels 리스트엔 카운트 번호 추가 \n",
    "    Labels.append(i)\n",
    "\n",
    "#훈련할 데이터가 없다면 종료.\n",
    "if len(Labels) == 0:\n",
    "    print(\"There is no data to train.\")\n",
    "    exit()\n",
    "\n",
    "#Labels를 32비트 정수로 변환\n",
    "Labels = np.asarray(Labels, dtype=np.int32)\n",
    "#모델 생성 \n",
    "model = cv2.face.LBPHFaceRecognizer_create()\n",
    "#학습 시작 \n",
    "model.train(np.asarray(Training_Data), np.asarray(Labels))\n",
    "print(\"Model Training Complete!!!!!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Facial_Recognition_Part3.py\n",
    "- 얼굴잠금해제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] 지정된 경로를 찾을 수 없습니다: 'faces/'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-f9f0290d2da4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m##### 여기서부터는 Part2.py와 동일\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mdata_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'faces/'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0monlyfiles\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mf\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlistdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_path\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0misfile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_path\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[0mTraining_Data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mLabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfiles\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0monlyfiles\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] 지정된 경로를 찾을 수 없습니다: 'faces/'"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "##### 여기서부터는 Part2.py와 동일 \n",
    "data_path = 'faces/'\n",
    "onlyfiles = [f for f in listdir(data_path) if isfile(join(data_path,f))]\n",
    "Training_Data, Labels = [], []\n",
    "for i, files in enumerate(onlyfiles):\n",
    "    image_path = data_path + onlyfiles[i]\n",
    "    images = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    if images is None:\n",
    "        continue    \n",
    "    Training_Data.append(np.asarray(images, dtype=np.uint8))\n",
    "    Labels.append(i)\n",
    "if len(Labels) == 0:\n",
    "    print(\"There is no data to train.\")\n",
    "    exit()\n",
    "Labels = np.asarray(Labels, dtype=np.int32)\n",
    "model = cv2.face.LBPHFaceRecognizer_create()\n",
    "model.train(np.asarray(Training_Data), np.asarray(Labels))\n",
    "print(\"Model Training Complete!!!!!\")\n",
    "#### 여기까지 Part2.py와 동일 \n",
    "\n",
    "#### 여긴 Part1.py와 거의 동일 \n",
    "face_classifier = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "\n",
    "def face_detector(img, size = 0.5):\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_classifier.detectMultiScale(gray,1.3,5)\n",
    "    if faces is():\n",
    "        return img,[]\n",
    "    for(x,y,w,h) in faces:\n",
    "        cv2.rectangle(img, (x,y),(x+w,y+h),(0,255,255),2)\n",
    "        roi = img[y:y+h, x:x+w]\n",
    "        roi = cv2.resize(roi, (200,200))\n",
    "    return img,roi   #검출된 좌표에 사각 박스 그리고(img), 검출된 부위를 잘라(roi) 전달\n",
    "#### 여기까지 Part1.py와 거의 동일 \n",
    "#카메라 열기 \n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    #카메라로 부터 사진 한장 읽기 \n",
    "    ret, frame = cap.read()\n",
    "    # 얼굴 검출 시도 \n",
    "    image, face = face_detector(frame)\n",
    "    try:\n",
    "        #검출된 사진을 흑백으로 변환 \n",
    "        face = cv2.cvtColor(face, cv2.COLOR_BGR2GRAY)\n",
    "        #위에서 학습한 모델로 예측시도\n",
    "        result = model.predict(face)\n",
    "        #result[1]은 신뢰도이고 0에 가까울수록 자신과 같다는 뜻이다. \n",
    "        if result[1] < 500:\n",
    "            #????? 어쨋든 0~100표시하려고 한듯 \n",
    "            confidence = int(100*(1-(result[1])/300))\n",
    "            # 유사도 화면에 표시 \n",
    "            display_string = str(confidence)+'% Confidence it is user'\n",
    "        cv2.putText(image,display_string,(100,120), cv2.FONT_HERSHEY_COMPLEX,1,(250,120,255),2)\n",
    "        #75 보다 크면 동일 인물로 간주해 UnLocked! \n",
    "        if confidence > 75:\n",
    "            cv2.putText(image, \"Unlocked\", (250, 450), cv2.FONT_HERSHEY_COMPLEX, 1, (0, 255, 0), 2)\n",
    "            cv2.imshow('Face Cropper', image)\n",
    "        else:\n",
    "           #75 이하면 타인.. Locked!!! \n",
    "            cv2.putText(image, \"Locked\", (250, 450), cv2.FONT_HERSHEY_COMPLEX, 1, (0, 0, 255), 2)\n",
    "            cv2.imshow('Face Cropper', image)\n",
    "    except:\n",
    "        #얼굴 검출 안됨 \n",
    "        cv2.putText(image, \"Face Not Found\", (250, 450), cv2.FONT_HERSHEY_COMPLEX, 1, (255, 0, 0), 2)\n",
    "        cv2.imshow('Face Cropper', image)\n",
    "        pass\n",
    "    if cv2.waitKey(1)==13: #enter\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
